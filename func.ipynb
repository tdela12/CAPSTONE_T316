{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122dad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def top_n_categories(y_true, y_pred, features_df, feature_col, top_n=5, error_type=\"mae\"):\n",
    "    \"\"\"\n",
    "    Compute top N categories (best and worst) by average error for a given feature,\n",
    "    including category frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : pandas Series (array-like)\n",
    "        Ground truth values\n",
    "    y_pred : pandas Series (array-like)\n",
    "        Model predictions\n",
    "    features_df : DataFrame\n",
    "        DataFrame with features (aligned with y_true/y_pred)\n",
    "    feature_col : str\n",
    "        Feature containing the categories groupby\n",
    "    top_n : int, default=5\n",
    "        Number of top categories to return\n",
    "    error_type : str, default=\"mae\"\n",
    "        Error metric: mae (mean absolute error) or mse (mean squared error)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "      \"y_true\": y_true,\n",
    "      \"y_pred\": y_pred,\n",
    "      \"error\": y_true - y_pred\n",
    "    })\n",
    "\n",
    "    df[feature_col] = features_df[feature_col].values\n",
    "    if error_type == \"mae\":\n",
    "      df[\"err\"] = df[\"error\"].abs()\n",
    "\n",
    "\n",
    "    if error_type == \"mse\":\n",
    "      df[\"err\"] = df[\"error\"]**2\n",
    "      \n",
    "\n",
    "\n",
    "    grouped = df.groupby(feature_col).aggregate(avg_error=(\"err\", \"mean\"),frequency=(\"err\", \"count\"))\n",
    "\n",
    "    sorted = grouped.sort_values(\"avg_error\")\n",
    "    best = sorted.head(top_n).reset_index()\n",
    "    worst = sorted.tail(top_n).reset_index()\n",
    "    \n",
    "    print(\"Top 5 Best Categories:\")\n",
    "    print(best)\n",
    "\n",
    "    print(\"\\nTop 5 Least Accurate Predictions:\")\n",
    "    print(worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute top N accurate samples (best and worst) by error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : pandas Series (array-like)\n",
    "        Ground truth values\n",
    "    y_pred : pandas Series (array-like)\n",
    "        Model predictions\n",
    "    \"\"\"\n",
    "    errors = np.abs(y_true - y_pred)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"error\": errors  })\n",
    "\n",
    "    sorted_results = results.sort_values(by=\"error\")\n",
    "    top5_accurate = sorted_results.head(5)\n",
    "    top5_inaccurate = sorted_results.tail(5)\n",
    "\n",
    "    print(\"Top 5 Most Accurate Predictions:\")\n",
    "    print(top5_accurate)\n",
    "\n",
    "    print(\"\\nTop 5 Least Accurate Predictions:\")\n",
    "    print(top5_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da80285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rand_sample_from_df(df, num_samples, model):\n",
    "    \"\"\"\n",
    "    Predict a random sample from the given dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas Series (array-like)\n",
    "        Dataframe to sample from\n",
    "    num_samples : Integer\n",
    "        Number of random samples to predict\n",
    "    model : \n",
    "        Trained model used to predict samples\n",
    "    \"\"\"\n",
    "    sample = df.sample(n=num_samples)\n",
    "    print(type(sample))\n",
    "    model.predict(sample)\n",
    "\n",
    "\n",
    "def test_single_sample_from_df(df, df_idx, model):\n",
    "    sample = df.iloc[df_idx]\n",
    "    print(type(sample))\n",
    "    model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38db9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def plot_residuals(y_true, y_pred):\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(y_pred, y_true)\n",
    "    plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()])\n",
    "\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"True values\")\n",
    "    plt.title(\"Predicted vs True\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals vs Predicted\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.histplot(residuals, kde=True, bins=30)\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.title(\"Histogram of Residuals\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    sm.qqplot(residuals, fit=True)\n",
    "    plt.title(\"Q-Q Plot of Residuals\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41eca57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
